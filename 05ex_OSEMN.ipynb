{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSEMN Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---> NB exs 1 to 3 are to be done by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# ---> to make sure graphs are not displayed in new windows, but here in the notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random # ---> even simpler with numpy\n",
    "import json\n",
    "import csv \n",
    "rng=np.random.Generator(np.random.PCG64()) # ---> \"Generator\" class object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Create a random list of numbers and then save it to a text file named \"simple_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Libero\\LaboratoryOfComputationalPhysics_Y8\\data\\simple_data.txt\"\n",
    "# ---> will be created if it doesn't exist\n",
    "array=[x/1000 for x in range(0,1001)]\n",
    "numbers_list=random.choices(array, k=100)\n",
    "with open(path, mode='w') as f: # ---> \"open\" takes the path and gets the file\n",
    "    # ---> \"with-as\" block to avoid writing \"try\"/\"finally\" block, ie calling close(path) when the block is exited;\n",
    "    #      implemented through object of the \"context manager\" class\n",
    "    for number in numbers_list: \n",
    "        f.write(str(number)+'\\n')\n",
    "        # ---> method of the class io.TextIOWrapper, which is subclass of io.BufferedIOBase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Create a random matrix of 5x5 and then save it to a text file named \"data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as before\n",
    "path=r\"C:\\Users\\Libero\\LaboratoryOfComputationalPhysics_Y8\\data\\data.txt\"\n",
    "numbers_matrix=rng.random(size=(5,5))\n",
    "with open(path, mode='w') as f:\n",
    "    f.write(str(numbers_matrix)) # ---> will save with parentheses et\n",
    "# ---> or: for i in... for j in... f.write(numbers_matrix[i,j])\n",
    "#      with appropriate newlines and spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Load the saved txt file of point 2 and convert it to a csv file (by hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Libero\\LaboratoryOfComputationalPhysics_Y8\\data\\data.txt\"\n",
    "finalpath=r\"C:\\Users\\Libero\\LaboratoryOfComputationalPhysics_Y8\\data\\data.csv\"\n",
    "with open(path, mode='r') as f: \n",
    "    content=f.read()\n",
    "with open(finalpath, mode='w') as g:\n",
    "    for i,charachter in enumerate(content): # ---> NB this to access previous charachter\n",
    "        if ((charachter==\"[\") or (charachter==\"]\")):\n",
    "            pass # ---> ie go to next \"for\" iteration\n",
    "        elif (charachter==\"\\n\"):\n",
    "            g.write(charachter)\n",
    "        elif (charachter==\" \"):\n",
    "            #if (i==0): pass\n",
    "            if ((content[i-1]==\" \") or (content[i-1]==\"\\n\")):\n",
    "                # ---> NB to avoid commas at newline or double commas when double space\n",
    "                pass\n",
    "            else: \n",
    "                g.write(\",\") \n",
    "        else: # ---> if data charachter (digit or point)\n",
    "            g.write(charachter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. load the binary file named *credit_card.dat* and convert the data into the real credit-card number.\n",
    "Each line correspond to a credit card number.\n",
    "Each character is composed by 6 bit (even the space) and the last 4 bit are just a padding\n",
    "\n",
    "**hint**: use the `chr()` function to convert a number to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccdat_path=r\"C:\\Users\\Libero\\LaboratoryOfComputationalPhysics_Y8\\credit_card.dat\"\n",
    "cctxt_path=r\"C:\\Users\\Libero\\LaboratoryOfComputationalPhysics_Y8\\data\\credit_card.txt\"\n",
    "with open(ccdat_path, mode='r') as f, open(cctxt_path, mode='w') as g:\n",
    "    # ---> NB \"r\" mode bc NOT really a binary file (even tho \".dat\"), just 0s and 1s with newlines\n",
    "    word_size=6\n",
    "    for line in f:\n",
    "    # ---> NB each line of the file is considered an \"element\" of the file object\n",
    "        dec_sequence_str=''\n",
    "        for i in range(0, (len(line)-4), word_size):\n",
    "            bit_word=line[i:i+word_size] \n",
    "            thischarachter=chr(int(bit_word,2)) # ---> NB simply this!\n",
    "            dec_sequence_str+=thischarachter\n",
    "        g.write(dec_sequence_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Load the file \"user_data.json\", filter the data by the \"CreditCardType\" field equals to \"American Express\". Than save the data to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Libero\\LaboratoryOfComputationalPhysics_Y8\\user_data.json\"\n",
    "finalpath=r\"C:\\Users\\Libero\\LaboratoryOfComputationalPhysics_Y8\\data\\user_data.csv\"\n",
    "with open(path, mode='r') as jf:\n",
    "    d_list=json.load(jf) # ---> NB this to load a file-like object\n",
    "d_filtered=[dictionary for dictionary in d_list if (dictionary['CreditCardType']==\"American Express\")]\n",
    "# ---> *dictionary is unordered and changeable object\n",
    "with open(finalpath, 'w', newline='') as f:\n",
    "    header=d_filtered[0].keys()\n",
    "    writer=csv.DictWriter(f, fieldnames=header) # ---> NB this\n",
    "    writer.writeheader() # ---> NB this\n",
    "    writer.writerows(d_filtered) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Load the file from this url: [https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1](https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1) with Pandas. \n",
    "+ Explore the data (see the info of the data)\n",
    "+ Draw the istogram of the 'class' field. Describe what you see\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1\"\n",
    "df=pd.read_csv(url)\n",
    "df.hist(\"class\")\n",
    "plt.show()\n",
    "# ---> two classes, data almost equally distributed in them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Load the remote file [https://www.dropbox.com/s/vkl89yce7xjdq4n/regression_generated.csv?dl=1](https://www.dropbox.com/s/vkl89yce7xjdq4n/regression_generated.csv?dl=1) with Pandas and plot a scatter plot all possible combination of the following fields:\n",
    "    \n",
    "  + features_1\n",
    "  + features_2\n",
    "  + features_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.dropbox.com/s/vkl89yce7xjdq4n/regression_generated.csv?dl=1\"\n",
    "df=pd.read_csv(url)\n",
    "features=[\"features_1\", \"features_2\", \"features_3\"]\n",
    "for i in range(len(features)):\n",
    "    first_feature=features[i]\n",
    "    for j in range(i+1, len(features)):\n",
    "        second_feature=features[j]\n",
    "        df.plot.scatter(first_feature,second_feature)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Load the same file of point 6, and convert the file to json with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.dropbox.com/s/vkl89yce7xjdq4n/regression_generated.csv?dl=1\"\n",
    "data=pd.read_csv(url)\n",
    "data.to_json(\"regression_generated.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
