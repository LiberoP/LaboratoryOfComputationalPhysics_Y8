{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **PCA on 3D dataset**\n",
    "\n",
    "* Generate a dataset with 3 features each with N entries (N being ${\\cal O}(1000)$). With $N(\\mu,\\sigma)$ the normal distribution with mean $\\mu$ and $\\sigma$ standard deviation, generate the 3 variables $x_{1,2,3}$ such that:\n",
    "    * $x_1$ is distributed as $N(0,1)$\n",
    "    * $x_2$ is distributed as $x_1+N(0,3)$\n",
    "    * $x_3$ is given by $2x_1+x_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg as la\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1000\n",
    "rng=np.random.default_rng(seed=94)\n",
    "x1=rng.normal(0.,1.,N)\n",
    "x2=rng.normal(0.,3.,N)\n",
    "x3=2*x1+x2\n",
    "data_matrix=np.concatenate((x1[:,None], x2[:,None], x3[:,None]), axis=1)\n",
    "print(data_matrix, data_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the eigenvectors and eigenvalues of the covariance matrix of the dataset\n",
    "* Find the eigenvectors and eigenvalues using SVD (---> on data matrix). Check that the two procedures yield to same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_centered=x1-x1.mean()\n",
    "x2_centered=x2-x2.mean()\n",
    "x3_centered=x3-x3.mean()\n",
    "data_matrix_centered=np.concatenate((x1_centered[:,None], x2_centered[:,None], x3_centered[:,None]), axis=1)\n",
    "covariance_matrix=(data_matrix_centered.T).dot(data_matrix_centered)/(N-1) # ---> NB the N-1\n",
    "#print(covariance_matrix)\n",
    "#element=[element in covariance_matrix if element > 1 else NaN] # ---> fix?\n",
    "#print(element)\n",
    "\n",
    "eig_vals, eig_vects= la.eig(covariance_matrix) # ---> NB eig(cov)\n",
    "print(np.real_if_close(eig_vals), '\\n \\n', eig_vects, '\\n \\n')\n",
    "\n",
    "U, spectrum, Vt = la.svd(data_matrix_centered) # ---> could also divide by sqrt(N-1) here and forget about it later\n",
    "# ---> NB svd(data_ctrd)\n",
    "print(U, '\\n \\n', spectrum, '\\n \\n', Vt)\n",
    "# ---> SVD algo also orders eigvals->eigvects from largest to smallest\n",
    "\n",
    "print(np.allclose(np.sort(eig_vals)[::-1], spectrum**2/(N-1))) # ---> also try it for matrix? (as an exercise)\n",
    "# ---> NB the **2 / N-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What percent of the total dataset's variability is explained by the principal components? Given how the dataset was constructed, do these make sense? Reduce the dimensionality of the system so that at least 99% of the total variability is retained.\n",
    "* Redefine the data in the basis yielded by the PCA procedure\n",
    "* Plot the data points in the original and the new coordinates as a set of scatter plots. Your final figure should have 2 rows of 3 plots each, where the columns show the (0,1), (0,2) and (1,2) projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---> For \"variability\" they mean the sum (trace) of the new eigenvalues normalised by the sum of the original ones\n",
    "initial_trace=covariance_matrix.trace()\n",
    "# ---> let's try to discard one dimension:\n",
    "n_rv=data_matrix.shape[1]\n",
    "new_spectrum=(np.sort(eig_vals)[::-1])[:(n_rv-1)]\n",
    "#print(new_spectrum)\n",
    "# ---> then two:\n",
    "new_variability=np.sum(new_spectrum)/initial_trace\n",
    "print(new_variability) # ---> how to approx correctly?\n",
    "new_new_spectrum=(np.sort(eig_vals)[::-1])[:(n_rv-2)]\n",
    "new_new_variability=np.sum(new_new_spectrum)/initial_trace\n",
    "print(new_new_variability)\n",
    "# ---> keep 2 dimensions (as expected)\n",
    "\n",
    "new_eig_vects=eig_vects[:,[0,2]] \n",
    "reduced_data_matrix_centered=np.dot(data_matrix_centered, new_eig_vects) # ---> NB eig vects are on columns!\n",
    "print(new_eig_vects)\n",
    "# --->  data_matrix_centered everywhere in this cell\n",
    "\n",
    "data_matrix_centered_new_base=np.dot(data_matrix_centered, eig_vects)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12,7)) # ---> NB the syntax\n",
    "acc=0\n",
    "for i in range(2):\n",
    "    for j in range(i+1,3):\n",
    "        #print(\"j:\",j)\n",
    "        axes[0,acc].scatter(data_matrix_centered[:,i], data_matrix_centered[:,j], color='g')\n",
    "        axes[0,acc].set_xlabel(f\"x{i+1}\")\n",
    "        axes[0,acc].set_ylabel(f\"x{j+1}\")\n",
    "        axes[1,acc].scatter(data_matrix_centered_new_base[:,i], data_matrix_centered_new_base[:,j], color='b')\n",
    "        axes[1,acc].set_xlabel(f\"x{i+1}\")\n",
    "        axes[1,acc].set_ylabel(f\"x{j+1}\")\n",
    "        #print(\"acc:\",acc)\n",
    "        acc=acc+1\n",
    "# ---> TODO: add legend. ax titles, fig title?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **PCA on a nD dataset**\n",
    "\n",
    "Start from the dataset you have genereted in the previous exercise and add uncorrelated random noise. Such noise should be represented by other 10 uncorrelated variables normal distributed, with standard deviation much smaller (say, a factor 50) than those used to generate the $x_1$ and $x_2$.\n",
    "\n",
    "Repeat the PCA procedure and compare the results with what you obtained before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---> everything the same, 10 new columns\n",
    "n=10\n",
    "epsilon=0.1\n",
    "noise_matrix=rng.normal(0.,0.1,(N,n)) # ---> NB this is the meaning of \"random noise\" here\n",
    "noise_matrix_centered=noise_matrix-noise_matrix.mean(axis=0)\n",
    "data_matrix_centered=np.concatenate((x1_centered[:,None], x2_centered[:,None],\n",
    "                                     x3_centered[:,None], noise_matrix_centered), axis=1)\n",
    "n_rv=data_matrix_centered.shape[1]\n",
    "_, spectrum, Vt = la.svd(data_matrix_centered)\n",
    "sorted_eig_vals=spectrum**2/(N-1)\n",
    "sorted_eig_vects=Vt # ---> the rows this time, NOT the columns\n",
    "initial_trace=np.sum(sorted_eig_vals)\n",
    "print(initial_trace)\n",
    "# ---> let's try to discard one dimension at a time:\n",
    "i_max=-1\n",
    "new_variability=1\n",
    "new_eig_vects=sorted_eig_vects\n",
    "for i in range(1,n_rv):\n",
    "    new_spectrum=sorted_eig_vals[:(n_rv-i)]\n",
    "    previous_variability=new_variability # ---> of previous cycle\n",
    "    new_variability=np.sum(new_spectrum)/initial_trace\n",
    "    print(i,new_variability)\n",
    "    if (new_variability<0.99):\n",
    "        i_max=i-1 # ---> of previous cycle\n",
    "        new_variability=previous_variability\n",
    "        new_eig_vects=sorted_eig_vects[:(n_rv-i_max),:]\n",
    "        # ---> eg if all to keep: n_rv-(1-1)= n_rv therefore original vector\n",
    "        break\n",
    "# --> check this?\n",
    "print(i_max,'\\n \\n', new_variability,'\\n \\n', new_eig_vects)\n",
    "data_matrix_centered_new_base=np.dot(data_matrix_centered, sorted_eig_vects.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(nrows=2, ncols=17)\n",
    "#acc=0\n",
    "#for i in range(2):\n",
    "#    for j in range(i+1,13):\n",
    "#        axes[0,acc].scatter(data_matrix_centered[:,i], data_matrix_centered[:,j], color='g')\n",
    "#        axes[0,acc].set_xlabel(f\"x{i+1}\")\n",
    "#        axes[0,acc].set_ylabel(f\"x{j+1}\")\n",
    "#        axes[1,acc].scatter(data_matrix_centered_new_base[:,i], data_matrix_centered_new_base[:,j], color='b')\n",
    "#        axes[1,acc].set_xlabel(f\"x{i+1}\")\n",
    "#        axes[1,acc].set_ylabel(f\"x{j+1}\")\n",
    "#        acc=acc+1\n",
    "\n",
    "# ---> TODO: draw some USEFUL graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 \\. **Looking at an oscillating spring** (optional)\n",
    "\n",
    "Imagine you have $n$ cameras looking at a spring oscillating along the $x$ axis. Each  camera record the motion of the spring looking at it along a given direction defined by the pair $(\\theta_i, \\phi_i)$, the angles in spherical coordinates. \n",
    "\n",
    "Start from the simulation of the records (say ${\\cal O}(1000)$) of the spring's motion along the x axis, assuming a little random noise affects the measurements along the $y$. Rotate such dataset to emulate the records of each camera.\n",
    "\n",
    "Perform a Principal Component Analysis on the thus obtained dataset, aiming at finding the only one coordinate that really matters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = 0, x = A cos(omega * t)\n",
    "# unclear what this \"rotation\" should be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **PCA on the MAGIC dataset** (optional)\n",
    "\n",
    "Perform a PCA on the magic04.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset and its description on the proper data directory\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data -P ~/data/\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.names -P ~/data/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
